{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XIh-eN66d3lO"
      },
      "outputs": [],
      "source": [
        "import pickle\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "\n",
        "# Attempt to load the model\n",
        "try:\n",
        "    with open('C:/Users/LENOVO/Documents/mini project/model.p', 'rb') as file:\n",
        "        model_dict = pickle.load(file)\n",
        "    model = model_dict['model']\n",
        "    print(\"Model loaded successfully.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error loading model: {e}\")\n",
        "    model = None\n",
        "\n",
        "# Initialize video capture\n",
        "cap = cv2.VideoCapture(0)\n",
        "\n",
        "# Initialize MediaPipe Hands\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "hands = mp_hands.Hands(static_image_mode=False, min_detection_confidence=0.3, max_num_hands=2)\n",
        "\n",
        "# Define labels\n",
        "labels_dict = {0: 'A', 1: 'B', 2: 'C', 3: 'D', 4: 'E', 5: 'F', 6: 'G', 7: 'H', 8: 'I', 9: 'J', 10: 'K', 11: 'L', 12: 'M', 13: 'N', 14: 'O', 15: 'P', 16: 'Q', 17: 'R', 18: 'S', 19: 'T', 20: 'U', 21: 'V', 22: 'W', 23: 'X', 24: 'Y', 25: 'Z'}\n",
        "\n",
        "def normalize_features(features):\n",
        "    # Normalize features if needed, e.g., between 0 and 1\n",
        "    return features\n",
        "\n",
        "while True:\n",
        "    # Capture frame-by-frame\n",
        "    ret, frame = cap.read()\n",
        "\n",
        "    if not ret:\n",
        "        print(\"Failed to grab frame\")\n",
        "        break\n",
        "\n",
        "    H, W, _ = frame.shape\n",
        "\n",
        "    # Convert the frame to RGB\n",
        "    frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "    # Process the frame with MediaPipe Hands\n",
        "    results = hands.process(frame_rgb)\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        combined_features = []\n",
        "\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            x_ = [landmark.x for landmark in hand_landmarks.landmark]\n",
        "            y_ = [landmark.y for landmark in hand_landmarks.landmark]\n",
        "\n",
        "            # Extract features from each hand\n",
        "            data_aux = []\n",
        "            for i in range(21):\n",
        "                data_aux.append(x_[i] - min(x_))\n",
        "                data_aux.append(y_[i] - min(y_))\n",
        "\n",
        "            combined_features.extend(data_aux)\n",
        "\n",
        "        # Ensure combined_features length matches model expectation (84 features)\n",
        "        if len(combined_features) != 84:\n",
        "            print(f\"Feature length mismatch: Expected 84, but got {len(combined_features)}\")\n",
        "            continue\n",
        "\n",
        "        # Normalize features if needed\n",
        "        combined_features = normalize_features(combined_features)\n",
        "\n",
        "        # Predict the character\n",
        "        if model is not None:\n",
        "            try:\n",
        "                prediction = model.predict([np.asarray(combined_features)])\n",
        "                predicted_character = labels_dict.get(int(prediction[0]), \"Unknown\")\n",
        "                print(f\"Predicted Character: {predicted_character}\")\n",
        "            except Exception as e:\n",
        "                print(f\"Prediction error: {e}\")\n",
        "                predicted_character = \"Error\"\n",
        "        else:\n",
        "            predicted_character = \"Model not available\"\n",
        "\n",
        "        # Draw landmarks and prediction on the frame\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                frame,\n",
        "                hand_landmarks,\n",
        "                mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "        # Calculate bounding box for both hands combined\n",
        "        all_x = [landmark.x for hand_landmarks in results.multi_hand_landmarks for landmark in hand_landmarks.landmark]\n",
        "        all_y = [landmark.y for hand_landmarks in results.multi_hand_landmarks for landmark in hand_landmarks.landmark]\n",
        "\n",
        "        x_min, x_max = min(all_x) * W, max(all_x) * W\n",
        "        y_min, y_max = min(all_y) * H, max(all_y) * H\n",
        "\n",
        "        x1 = int(x_min) - 10\n",
        "        y1 = int(y_min) - 10\n",
        "        x2 = int(x_max) + 10\n",
        "        y2 = int(y_max) + 10\n",
        "\n",
        "        # Draw bounding box and text\n",
        "        cv2.rectangle(frame, (x1, y1), (x2, y2), (0, 0, 0), 4)\n",
        "        cv2.putText(frame, predicted_character, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 1.3, (0, 0, 0), 3, cv2.LINE_AA)\n",
        "    else:\n",
        "        print(\"No hand landmarks detected\")\n",
        "\n",
        "    # Display the frame\n",
        "    cv2.imshow('frame', frame)\n",
        "\n",
        "    # Break the loop on 'q' key press\n",
        "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "        break\n",
        "\n",
        "# Release the capture and close windows\n",
        "cap.release()\n",
        "cv2.destroyAllWindows()"
      ]
    }
  ]
}